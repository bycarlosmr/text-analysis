{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: \n",
    "\n",
    "    - Given a list of docuemnts, determine the topic.\n",
    "    - Then aggregrate the documents and print the topic the documents belong too.\n",
    "    \n",
    "**Example**:\n",
    "    \n",
    "    Data\n",
    "    \n",
    "    it's very hot outside summer\n",
    "    there are not many flowers in winter\n",
    "    in the winter we eat hot food\n",
    "    in the summer we go to the sea\n",
    "    in winter we used many clothes\n",
    "    in summer we are on vacation\n",
    "    winter and summer are two seasons of the year\n",
    "    \n",
    "   **Output**\n",
    "    \n",
    "    Topic 1\n",
    "    it's very hot outside summer\n",
    "    in the summer we go to the sea\n",
    "    in summer we are on vacation\n",
    "    winter and summer are two seasons of the year\n",
    "\n",
    "    Topic 2\n",
    "    there are not many flowers in winter\n",
    "    in the winter we eat hot food\n",
    "    in winter we used many clothes\n",
    "    winter and summer are two seasons of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are the sample documents combining together to form a corpus.\n",
    "\n",
    "comments = ['it is very hot outside summer', 'there are not many flowers in winter','in the winter we eat hot food',\n",
    "        'in the summer we go to the sea','in winter we used many clothes','in summer we are on vacation',\n",
    "        'winter and summer are two seasons of the year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the required libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it is very hot outside summer',\n",
       " 'there are not many flowers in winter',\n",
       " 'in the winter we eat hot food',\n",
       " 'in the summer we go to the sea',\n",
       " 'in winter we used many clothes',\n",
       " 'in summer we are on vacation',\n",
       " 'winter and summer are two seasons of the year']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components = 2, learning_method = \"batch\", max_iter = 25, random_state = 0)\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis = 1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = np.argsort(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in summer we are on vacation\n",
      "\n",
      "in the summer we go to the sea\n",
      "\n",
      "in the winter we eat hot food\n",
      "\n",
      "in winter we used many clothes\n",
      "\n",
      "it is very hot outside summer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in docs[:5]:\n",
    "    print(\" \".join(comments[i].split(\",\")[:2]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<WordListCorpusReader in '.../corpora/names' (not loaded yet)>\n"
     ]
    }
   ],
   "source": [
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
